{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10933baa-75a2-4fae-829f-ab7a20be95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0f2c7-e281-496c-9358-0a67e9d18dc0",
   "metadata": {},
   "source": [
    "## Part 1: Working with JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fe9e86-d586-41bb-bb98-9e56c0c5d11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: USC00305800\n",
      "Location: {'latitude': 40.7789, 'longitude': -73.9692}\n",
      "First observation: {'date': '2023-01-01', 'temperature': 32, 'precipitation': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sample_json = '''\n",
    "{\n",
    "  \"station\": \"USC00305800\",\n",
    "  \"name\": \"New York Central Park\",\n",
    "  \"location\": {\n",
    "    \"latitude\": 40.7789,\n",
    "    \"longitude\": -73.9692\n",
    "  },\n",
    "  \"observations\": [\n",
    "    {\"date\": \"2023-01-01\", \"temperature\": 32, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-02\", \"temperature\": 28, \"precipitation\": 0.5},\n",
    "    {\"date\": \"2023-01-03\", \"temperature\": 35, \"precipitation\": 0.0},\n",
    "    {\"date\": \"2023-01-04\", \"temperature\": 38, \"precipitation\": 0.2},\n",
    "    {\"date\": \"2023-01-05\", \"temperature\": 41, \"precipitation\": 0.0}\n",
    "  ]\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON\n",
    "data = json.loads(sample_json)\n",
    "\n",
    "# Access nested data\n",
    "print(\"Station:\", data['station'])\n",
    "print(\"Location:\", data['location'])\n",
    "print(\"First observation:\", data['observations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd084930-bcb4-4901-ace5-8d59f3ace074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date, Temperature\n",
      "2023-01-01 , 32\n",
      "2023-01-02 , 28\n",
      "2023-01-03 , 35\n",
      "2023-01-04 , 38\n",
      "2023-01-05 , 41\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract and print all dates and temperatures (8 points)\n",
    "print(\"Date, Temperature\")\n",
    "for obs in data['observations']:\n",
    "    print(obs['date'], \",\", obs['temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f93deea-7d57-4155-974d-2e178e3f7294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature: 34.8°F\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate average temperature (8 points)\n",
    "total_temp = 0\n",
    "count = 0\n",
    "for obs in data['observations']:\n",
    "    total_temp += obs['temperature']\n",
    "    count += 1\n",
    "\n",
    "avg_temp = total_temp / count\n",
    "print(f\"Average temperature: {avg_temp}°F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062129a2-bf60-4b12-bb8a-033e18c108fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days with precipitation:\n",
      "2023-01-02: 0.5\n",
      "2023-01-04: 0.2\n"
     ]
    }
   ],
   "source": [
    "# 3. Find days with precipitation (9 points)\n",
    "print(\"\\nDays with precipitation:\")\n",
    "for obs in data['observations']:\n",
    "    if obs['precipitation']>0:\n",
    "        print(f\"{obs['date']}: {obs['precipitation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c46db0-829f-4e26-897a-836281a7cf03",
   "metadata": {},
   "source": [
    "**Now try with a real API :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47bf472-4c2f-48b1-9c43-23a7b4c0c204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['coord', 'weather', 'base', 'main', 'visibility', 'wind', 'clouds', 'dt', 'sys', 'timezone', 'id', 'name', 'cod'])\n",
      "City: New York\n",
      "Weather: [{'id': 800, 'main': 'Clear', 'description': 'clear sky', 'icon': '01d'}]\n"
     ]
    }
   ],
   "source": [
    "# Use a real weather API (you may need to sign up for a free API key)\n",
    "# Example APIs: OpenWeatherMap, NOAA, Weather.gov\n",
    "# YOUR CODE HERE \n",
    "\n",
    "api_key = 'd9b1d9b91ef6b0a5af404acedf850b20'\n",
    "city = 'New York City'\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "nyc_data = response.json()\n",
    "\n",
    "print(nyc_data. keys())\n",
    "\n",
    "print (\"City:\", nyc_data [\"name\"])\n",
    "print (f\"Weather: {nyc_data ['weather']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f418286-5f43-4ac4-9305-05c5efca98ad",
   "metadata": {},
   "source": [
    "## Part 2: Downloading Files with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ead5c1-6ce7-428c-ba4f-740b2821c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /home/jb5222/.cache/pooch/458dad453f6a48e510cd544bef1854e3-air_quality_no2.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import pooch\n",
    "import os\n",
    "\n",
    "# Set up Pooch to download a file\n",
    "# This example downloads a small air quality dataset\n",
    "file_path = pooch.retrieve(\n",
    "    url=\"https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv\",\n",
    "    known_hash=None,\n",
    ")\n",
    "\n",
    "print(\"File downloaded to:\", file_path)\n",
    "print(\"File exists:\", os.path.exists(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2e3136-9b55-4104-b4f0-4afde2a59551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 31984 bytes\n",
      "Number of lines: 1036\n"
     ]
    }
   ],
   "source": [
    "# 1. Verify the file was downloaded (5 points)\n",
    "# Check the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "print(f\"File size: {file_size} bytes\")\n",
    "\n",
    "# YOUR CODE HERE: open the file and count how many lines it has\n",
    "line_count = 0 \n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line_count +=1\n",
    "print(f\"Number of lines: {line_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04795e40-3b95-4641-ad6f-d2f4d6896f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My file downloaded to: /home/jb5222/.cache/pooch/091fa6f46c6d0e4f56f340e4282e9175-GLB.Ts+dSST.csv\n",
      "My file exists: True\n",
      "File size: 12878 bytes\n"
     ]
    }
   ],
   "source": [
    "# 2. Download another file (10 points)\n",
    "# Find a climate dataset online using the sources we talked about in lecture\n",
    "# Download it using Pooch\n",
    "# YOUR CODE HERE:\n",
    "# my_url = \"...\"\n",
    "# my_file = pooch.retrieve(url=my_url, known_hash=None)  # hash optional for first try\n",
    "# Print info about your downloaded file\n",
    "\n",
    "my_url=\"https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv\"\n",
    "\n",
    "my_file = pooch.retrieve(\n",
    "    my_url, \n",
    "    known_hash=None)\n",
    "\n",
    "print(\"My file downloaded to:\", my_file)\n",
    "print(\"My file exists:\", os.path.exists(my_file))\n",
    "\n",
    "my_file_size = os.path.getsize(my_file)\n",
    "print(f\"File size: {my_file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd005143-da3d-4a56-a99e-54b7cb816385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Inventory:\n",
      "1. meteorites.csv - NASA meteorite landings\n",
      "2. air_quality_no2.csv - Air quality NO2 measurements\n",
      "3. GLB.Ts+dSST.csv – NASA global temperature anomalies\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a data inventory (5 points)\n",
    "# List all the files you've downloaded in this assignment\n",
    "print(\"\\nData Inventory:\")\n",
    "print(\"1. meteorites.csv - NASA meteorite landings\")\n",
    "print(\"2. air_quality_no2.csv - Air quality NO2 measurements\")\n",
    "# YOUR CODE HERE: add your file from task 2\n",
    "print(\"3. GLB.Ts+dSST.csv – NASA global temperature anomalies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f3cd8-9d99-4fd2-b422-b99b24409016",
   "metadata": {},
   "source": [
    "## Part 3: Understanding NetCDF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a6e23a-2f0b-45f8-863d-ca64f0040bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Dataset {\n",
      "    Float32 T[T = 324];\n",
      "    Float32 Y[Y = 360];\n",
      "    Float32 X[X = 720];\n",
      "    Grid {\n",
      "     ARRAY:\n",
      "        Float32 rain[T = 324][Y = 360][X = 720];\n",
      "     MAPS:\n",
      "        Float32 T[T = 324];\n",
      "        Float32 Y[Y = 360];\n",
      "        Float32 X[X = 720];\n",
      "    } rain;\n",
      "} rain;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# OPeNDAP provides metadata in different formats\n",
    "# We'll get basic info about a climate dataset\n",
    "\n",
    "base_url = \"http://iridl.ldeo.columbia.edu/expert/SOURCES/.NOAA/.NCEP/.CPC/.UNIFIED_PRCP/.GAUGE_BASED/.GLOBAL/.v1p0/.Monthly/.RETRO/.rain/dods\"\n",
    "\n",
    "# Get DDS (Dataset Descriptor Structure) - describes the structure\n",
    "dds_url = base_url + \".dds\"\n",
    "response = requests.get(dds_url)\n",
    "\n",
    "print(\"Dataset Structure:\")\n",
    "print(response.text[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f5764-71e7-4b22-81a0-ee62c180887a",
   "metadata": {},
   "source": [
    "#### 1. Identify dimensions and variables (5 points)\n",
    "Look at the DDS output above and answer:\n",
    "##### - What are the dimension names?\n",
    "The dimensions are time (T=324), longitude (X=720) and latitude (Y=360). \n",
    "\n",
    "##### - What is the main variable name?\n",
    "The name of the main variable is \"rain\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d27bd98-cbf8-4956-a337-ec65efa8f067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Attribute Structure:\n",
      "Attributes {\n",
      "    X {\n",
      "        String standard_name \"longitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 1;\n",
      "        String units \"degree_east\";\n",
      "    }\n",
      "    T {\n",
      "        Float32 pointwidth 1.0;\n",
      "        String calendar \"360\";\n",
      "        Int32 gridtype 0;\n",
      "        String units \"months since 1960-01-01\";\n",
      "    }\n",
      "    Y {\n",
      "        String standard_name \"latitude\";\n",
      "        Float32 pointwidth 0.5;\n",
      "        Int32 gridtype 0;\n",
      "        String units \"degree_north\";\n",
      "    }\n",
      "    rain {\n",
      "        Int32 pointwidth 0;\n",
      "        String standard_name \"lwe_precipitation_rate\";\n",
      "        Float32 file_missing_value -999.0;\n",
      "        String history \"Boxes with less than 0.0% dropped\";\n",
      "        Float32 missing_value NaN;\n",
      "        String units \"mm/day\";\n",
      "        String long_name \"Monthly Precipitation\";\n",
      "    }\n",
      "NC_GLOBAL {\n",
      "    String Conventions \"IRIDL\";\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Get data attributes (5 points)\n",
    "# DAS (Dataset Attribute Structure) contains metadata\n",
    "das_url = base_url + \".das\"\n",
    "# YOUR CODE HERE: make a request to das_url and print first 1000 characters\n",
    "response = requests.get(das_url)\n",
    "print(\"Dataset Attribute Structure:\")\n",
    "print(response.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09aa11b-c455-417d-ae38-1dc763de60d1",
   "metadata": {},
   "source": [
    "#### 3. Document what you learned (5 points)\n",
    "##### In a markdown cell, write:\n",
    "##### - What does this dataset contain?\n",
    "This dataset contains global monthly precipitation data from NOAA CPC Global Unified Gauge-Based Analysis.\n",
    "##### - What time period does it cover?\n",
    "It covers monthly data since January 1st, 1960.\n",
    "##### - What geographic region does it cover?\n",
    "This dataset has a global coverage as the 720x360 grid points at 0.5º resolution cover all 360º of longitude and 180º of latitude.\n",
    "##### - What are the units of the main variable?\n",
    "The units are mm/day.\n",
    "##### Find this info in the DAS output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo23",
   "language": "python",
   "name": "pangeo23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
